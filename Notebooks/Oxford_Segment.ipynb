{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a475f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Load Oxford Pets dataset from TFDS\n",
    "(train_ds, test_ds), info = tfds.load('oxford_iiit_pet:3.*.*', split=['train', 'test'], with_info=True)\n",
    "\n",
    "# Define preprocessing functions\n",
    "def preprocess_image(data):\n",
    "    image = tf.image.resize(data['image'], (32, 32))  # Resize image\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    label = tf.image.resize(data['segmentation_mask'], (32, 32))  # Resize label\n",
    "    label = tf.cast(label, tf.int32)  # Ensure labels are integers\n",
    "    \n",
    "    # Convert labels to one-hot categorical\n",
    "    num_classes = info.features['label'].num_classes\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    \n",
    "    # Reshape labels\n",
    "    label = tf.reshape(label, (32, 32, num_classes))  # Reshape to (32, 32, num_classes)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing to datasets\n",
    "train_ds = train_ds.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350eb520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (32, 32, 3)\n",
      "Label shape: (32, 32, 37)\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Label shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d1c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9744cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5c0eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 19s 90ms/step - loss: 1.2544 - accuracy: 0.5335\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 10s 90ms/step - loss: 0.9266 - accuracy: 0.5871\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.9036 - accuracy: 0.5988\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8876 - accuracy: 0.6085\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8686 - accuracy: 0.6169\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.8666 - accuracy: 0.6207\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8610 - accuracy: 0.6263\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8516 - accuracy: 0.6288\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 10s 85ms/step - loss: 0.8452 - accuracy: 0.6308\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 11s 98ms/step - loss: 0.8463 - accuracy: 0.6320\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 9s 77ms/step - loss: 0.8537 - accuracy: 0.6292\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.8516 - accuracy: 0.6300\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 10s 86ms/step - loss: 0.8436 - accuracy: 0.6323\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8488 - accuracy: 0.6302\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - 10s 83ms/step - loss: 0.8539 - accuracy: 0.6282\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - 10s 90ms/step - loss: 0.8476 - accuracy: 0.6313\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - 10s 90ms/step - loss: 0.8499 - accuracy: 0.6309\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.8645 - accuracy: 0.6258\n",
      "Epoch 19/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8546 - accuracy: 0.6277\n",
      "Epoch 20/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.8445 - accuracy: 0.6313\n",
      "Epoch 21/100\n",
      "115/115 [==============================] - 10s 91ms/step - loss: 0.8433 - accuracy: 0.6329\n",
      "Epoch 22/100\n",
      "115/115 [==============================] - 11s 89ms/step - loss: 0.8455 - accuracy: 0.6323\n",
      "Epoch 23/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8576 - accuracy: 0.6273\n",
      "Epoch 24/100\n",
      "115/115 [==============================] - 10s 87ms/step - loss: 0.8607 - accuracy: 0.6211\n",
      "Epoch 25/100\n",
      "115/115 [==============================] - 10s 89ms/step - loss: 0.8478 - accuracy: 0.6308\n",
      "Epoch 26/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8481 - accuracy: 0.6307\n",
      "Epoch 27/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.8461 - accuracy: 0.6325\n",
      "Epoch 28/100\n",
      "115/115 [==============================] - 11s 90ms/step - loss: 0.8717 - accuracy: 0.6214\n",
      "Epoch 29/100\n",
      "115/115 [==============================] - 11s 90ms/step - loss: 0.8527 - accuracy: 0.6270\n",
      "Epoch 30/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8448 - accuracy: 0.6314\n",
      "Epoch 31/100\n",
      "115/115 [==============================] - 11s 90ms/step - loss: 0.8421 - accuracy: 0.6329\n",
      "Epoch 32/100\n",
      "115/115 [==============================] - 10s 87ms/step - loss: 0.8409 - accuracy: 0.6328\n",
      "Epoch 33/100\n",
      "115/115 [==============================] - 11s 91ms/step - loss: 0.8469 - accuracy: 0.6314\n",
      "Epoch 34/100\n",
      "115/115 [==============================] - 10s 87ms/step - loss: 0.8420 - accuracy: 0.6325\n",
      "Epoch 35/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8421 - accuracy: 0.6327\n",
      "Epoch 36/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.8979 - accuracy: 0.5989\n",
      "Epoch 37/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.8946 - accuracy: 0.5988\n",
      "Epoch 38/100\n",
      "115/115 [==============================] - 11s 89ms/step - loss: 0.8874 - accuracy: 0.6008\n",
      "Epoch 39/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.8739 - accuracy: 0.6071\n",
      "Epoch 40/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8647 - accuracy: 0.6168\n",
      "Epoch 41/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.8628 - accuracy: 0.6162\n",
      "Epoch 42/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8603 - accuracy: 0.6199\n",
      "Epoch 00042: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d1075b2b50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eaeab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0541199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 11s 84ms/step - loss: 0.9390 - accuracy: 0.5914\n",
      "Test Loss: 0.9390224814414978\n",
      "Test Accuracy: 0.591357946395874\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad4de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f67d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\oxf_32_model.h5\")\n",
    "    \n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.layers[-4].output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca03709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20538483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 16s 89ms/step - loss: 1.0784 - accuracy: 0.5690\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 9s 82ms/step - loss: 0.9179 - accuracy: 0.5964\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 10s 91ms/step - loss: 0.9278 - accuracy: 0.5877\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 10s 90ms/step - loss: 0.9309 - accuracy: 0.5859\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 11s 89ms/step - loss: 0.9345 - accuracy: 0.5864\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.9178 - accuracy: 0.5887\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 10s 90ms/step - loss: 0.9044 - accuracy: 0.5953\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 11s 91ms/step - loss: 0.9038 - accuracy: 0.5984\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.9064 - accuracy: 0.5970\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.9200 - accuracy: 0.5936\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 11s 90ms/step - loss: 0.9442 - accuracy: 0.5833\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 11s 90ms/step - loss: 0.9323 - accuracy: 0.5882\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.9290 - accuracy: 0.5870\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.9306 - accuracy: 0.5893\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.9217 - accuracy: 0.5902\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.9256 - accuracy: 0.5906\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - 11s 91ms/step - loss: 0.9092 - accuracy: 0.5943\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.9112 - accuracy: 0.5946\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d579ab17f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462272ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "496dfc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 8s 62ms/step - loss: 0.9797 - accuracy: 0.5866\n",
      "Test Loss: 0.9797009229660034\n",
      "Test Accuracy: 0.5866425633430481\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b9b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd487aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\rnd_32_model.h5\")\n",
    "    \n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.layers[-4].output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e76b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e859cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 17s 94ms/step - loss: 1.1083 - accuracy: 0.5700\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 10s 86ms/step - loss: 0.8959 - accuracy: 0.6016\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.8879 - accuracy: 0.6113\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.8825 - accuracy: 0.6198\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 10s 91ms/step - loss: 0.9115 - accuracy: 0.6138\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 11s 91ms/step - loss: 0.9273 - accuracy: 0.5876\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 10s 89ms/step - loss: 0.9318 - accuracy: 0.5852\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 10s 89ms/step - loss: 0.9087 - accuracy: 0.5868\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 10s 90ms/step - loss: 0.9417 - accuracy: 0.5861\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 10s 86ms/step - loss: 0.9408 - accuracy: 0.5865\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.9104 - accuracy: 0.5886\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 12s 100ms/step - loss: 0.9107 - accuracy: 0.5939\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.9086 - accuracy: 0.5898\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.9036 - accuracy: 0.5921\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d57f9a6b20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0586a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 7s 55ms/step - loss: 0.9835 - accuracy: 0.5769\n",
      "Test Loss: 0.9834929704666138\n",
      "Test Accuracy: 0.5769003629684448\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d046a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1928444d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a7272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac19c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb799c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cb67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
