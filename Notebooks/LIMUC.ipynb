{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14666713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (9590, 32, 32, 3)\n",
      "Shape of Y_train_categorical: (9590, 4)\n",
      "Shape of X_test: (1686, 32, 32, 3)\n",
      "Shape of Y_test_categorical: (1686, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the paths to your dataset folders\n",
    "train_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\train_and_validation_sets\\train_and_validation_sets\"\n",
    "test_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\test_set\\test_set\"\n",
    "\n",
    "# Initialize empty lists for X_train, Y_train, X_test, and Y_test\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "# Initialize an empty list to store categorical labels\n",
    "categorical_labels = []\n",
    "\n",
    "# Define a function to read and preprocess images\n",
    "def process_images(folder_path, label, is_train_set=True):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path) and filename.endswith(\".bmp\"):  # Check if it's a file and ends with .bmp\n",
    "            # Open and resize the image to (32, 32, 3)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((32, 32))\n",
    "            img = img.convert(\"RGB\")\n",
    "            \n",
    "            # Convert image data to a NumPy array\n",
    "            img_array = np.array(img).astype('float32')  # Convert to float\n",
    "            \n",
    "            # Normalize the image data (optional)\n",
    "            img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "            \n",
    "            # Append the image data to the appropriate list\n",
    "            if is_train_set:\n",
    "                X_train.append(img_array)\n",
    "                Y_train.append(label)  # Append the numerical label\n",
    "            else:\n",
    "                X_test.append(img_array)\n",
    "                Y_test.append(label)  # Append the numerical label\n",
    "            \n",
    "            # Append the label for categorical encoding\n",
    "            categorical_labels.append(label)  # Append the numerical label\n",
    "\n",
    "# List the folders inside the training dataset directory\n",
    "train_folders = os.listdir(train_dataset_dir)\n",
    "\n",
    "# Create a label encoder for categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Loop through the training folders and process images\n",
    "for label, folder_name in enumerate(train_folders):\n",
    "    folder_path = os.path.join(train_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label)\n",
    "\n",
    "# List the folders inside the test dataset directory\n",
    "test_folders = os.listdir(test_dataset_dir)\n",
    "\n",
    "# Loop through the test folders and process images\n",
    "for label, folder_name in enumerate(test_folders):\n",
    "    folder_path = os.path.join(test_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label, is_train_set=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# Encode Y_train and Y_test categorically\n",
    "num_classes = len(np.unique(categorical_labels))\n",
    "  # Update this to match the number of classes\n",
    "\n",
    "# Convert Y_train and Y_test to NumPy arrays\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Make sure your labels are integers ranging from 0 to num_classes - 1\n",
    "Y_train = Y_train.astype(int)\n",
    "Y_test = Y_test.astype(int)\n",
    "\n",
    "# One-hot encode the labels\n",
    "Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "Y_test_categorical = to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# # Encode Y_train and Y_test categorically using the label encoder\n",
    "# num_classes = len(np.unique(Y_train))  # Automatically determine the number of classes\n",
    "# Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "# Y_test_categorical = to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# Check the shape of X_train, Y_train_categorical, X_test, and Y_test_categorical\n",
    "print(\"Shape of X_train:\", np.shape(X_train))\n",
    "print(\"Shape of Y_train_categorical:\", np.shape(Y_train_categorical))\n",
    "print(\"Shape of X_test:\", np.shape(X_test))\n",
    "print(\"Shape of Y_test_categorical:\", np.shape(Y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4596ee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mayo 0', 'Mayo 1', 'Mayo 2', 'Mayo 3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96837b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1def5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_1.00_224 (Functio  (None, 1, 1, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1024)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 4100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,232,964\n",
      "Trainable params: 3,211,076\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "#base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "base_model = MobileNet(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Change units to match the number of classes\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e7cde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 7s 29ms/step - loss: 0.9070 - accuracy: 0.6794 - val_loss: 31.6965 - val_accuracy: 5.2138e-04\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.5385 - accuracy: 0.7466 - val_loss: 20.5966 - val_accuracy: 0.0010\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.5013 - accuracy: 0.7663 - val_loss: 11.8314 - val_accuracy: 5.2138e-04\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4813 - accuracy: 0.7763 - val_loss: 13.0816 - val_accuracy: 0.0162\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4621 - accuracy: 0.7871 - val_loss: 13.4982 - val_accuracy: 0.0193\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.4311 - accuracy: 0.8012 - val_loss: 12.1383 - val_accuracy: 0.0334\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.4227 - accuracy: 0.8127 - val_loss: 11.8250 - val_accuracy: 0.0240\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.4182 - accuracy: 0.8130 - val_loss: 11.0826 - val_accuracy: 0.0328\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3644 - accuracy: 0.8393 - val_loss: 11.0365 - val_accuracy: 0.0266\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.3478 - accuracy: 0.8489 - val_loss: 12.3180 - val_accuracy: 0.0266\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3054 - accuracy: 0.8673 - val_loss: 13.4113 - val_accuracy: 0.0266\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2752 - accuracy: 0.8790 - val_loss: 12.5692 - val_accuracy: 0.0177\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.2451 - accuracy: 0.9000 - val_loss: 13.1232 - val_accuracy: 0.0266\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.2251 - accuracy: 0.9086 - val_loss: 12.5525 - val_accuracy: 0.0287\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.2096 - accuracy: 0.9162 - val_loss: 12.8293 - val_accuracy: 0.0302\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1883 - accuracy: 0.9251 - val_loss: 12.3872 - val_accuracy: 0.0235\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.1892 - accuracy: 0.9254 - val_loss: 12.1923 - val_accuracy: 0.0156\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.1668 - accuracy: 0.9372 - val_loss: 13.2835 - val_accuracy: 0.0323\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.1518 - accuracy: 0.9424 - val_loss: 12.2342 - val_accuracy: 0.0094\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.1468 - accuracy: 0.9446 - val_loss: 14.3116 - val_accuracy: 0.0308\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1225 - accuracy: 0.9540 - val_loss: 14.5182 - val_accuracy: 0.0167\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.1416 - accuracy: 0.9445 - val_loss: 12.8871 - val_accuracy: 0.0287\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1165 - accuracy: 0.9593 - val_loss: 13.2107 - val_accuracy: 0.0177\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1191 - accuracy: 0.9567 - val_loss: 14.8358 - val_accuracy: 0.0339\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1011 - accuracy: 0.9615 - val_loss: 15.0963 - val_accuracy: 0.0276\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0906 - accuracy: 0.9682 - val_loss: 13.6490 - val_accuracy: 0.0182\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0924 - accuracy: 0.9692 - val_loss: 15.7988 - val_accuracy: 0.0177\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1029 - accuracy: 0.9615 - val_loss: 14.6830 - val_accuracy: 0.0203\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0945 - accuracy: 0.9657 - val_loss: 14.0513 - val_accuracy: 0.0115\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0819 - accuracy: 0.9711 - val_loss: 15.0862 - val_accuracy: 0.0240\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0844 - accuracy: 0.9683 - val_loss: 16.2425 - val_accuracy: 0.0282\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.0865 - accuracy: 0.9668 - val_loss: 16.5537 - val_accuracy: 0.0151\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.0942 - accuracy: 0.9674 - val_loss: 16.2460 - val_accuracy: 0.0109\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0781 - accuracy: 0.9741 - val_loss: 14.8710 - val_accuracy: 0.0245\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0747 - accuracy: 0.9720 - val_loss: 17.5066 - val_accuracy: 0.0240\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0704 - accuracy: 0.9737 - val_loss: 16.1398 - val_accuracy: 0.0141\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.0856 - accuracy: 0.9702 - val_loss: 16.8723 - val_accuracy: 0.0224\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 0.0796 - accuracy: 0.9733 - val_loss: 14.3989 - val_accuracy: 0.0240\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.0534 - accuracy: 0.9807 - val_loss: 15.7138 - val_accuracy: 0.0182\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0691 - accuracy: 0.9772 - val_loss: 15.1902 - val_accuracy: 0.0209\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.0755 - accuracy: 0.9741 - val_loss: 12.9494 - val_accuracy: 0.0151\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0656 - accuracy: 0.9754 - val_loss: 19.6569 - val_accuracy: 0.0266\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.0567 - accuracy: 0.9798 - val_loss: 16.7607 - val_accuracy: 0.0308\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.0672 - accuracy: 0.9767 - val_loss: 15.8973 - val_accuracy: 0.0271\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 0.0534 - accuracy: 0.9807 - val_loss: 19.4263 - val_accuracy: 0.0282\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0503 - accuracy: 0.9807 - val_loss: 20.4422 - val_accuracy: 0.0334\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0537 - accuracy: 0.9828 - val_loss: 18.9465 - val_accuracy: 0.0224\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0535 - accuracy: 0.9816 - val_loss: 17.9904 - val_accuracy: 0.0292\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0643 - accuracy: 0.9760 - val_loss: 19.1174 - val_accuracy: 0.0224\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0547 - accuracy: 0.9814 - val_loss: 21.7642 - val_accuracy: 0.0276\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.0470 - accuracy: 0.9827 - val_loss: 20.1613 - val_accuracy: 0.0240\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0586 - accuracy: 0.9812 - val_loss: 17.7087 - val_accuracy: 0.0255\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0491 - accuracy: 0.9820 - val_loss: 18.2555 - val_accuracy: 0.0266\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0458 - accuracy: 0.9842 - val_loss: 18.7744 - val_accuracy: 0.0214\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0424 - accuracy: 0.9836 - val_loss: 14.7855 - val_accuracy: 0.0240\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0536 - accuracy: 0.9795 - val_loss: 16.7463 - val_accuracy: 0.0167\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 14.5873 - val_accuracy: 0.0193\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0398 - accuracy: 0.9851 - val_loss: 18.1657 - val_accuracy: 0.0328\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0365 - accuracy: 0.9875 - val_loss: 17.7715 - val_accuracy: 0.0261\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0404 - accuracy: 0.9853 - val_loss: 17.1806 - val_accuracy: 0.0167\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0329 - accuracy: 0.9872 - val_loss: 20.6729 - val_accuracy: 0.0250\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 15.9419 - val_accuracy: 0.0276\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 15.7775 - val_accuracy: 0.0250\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 6s 47ms/step - loss: 0.0342 - accuracy: 0.9888 - val_loss: 18.1426 - val_accuracy: 0.0292\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0458 - accuracy: 0.9838 - val_loss: 17.6849 - val_accuracy: 0.0302\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 18.1894 - val_accuracy: 0.0120\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0301 - accuracy: 0.9915 - val_loss: 15.7455 - val_accuracy: 0.0177\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 19.7020 - val_accuracy: 0.0188\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0549 - accuracy: 0.9812 - val_loss: 17.2025 - val_accuracy: 0.0261\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 0.0489 - accuracy: 0.9833 - val_loss: 17.5374 - val_accuracy: 0.0235\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0261 - accuracy: 0.9906 - val_loss: 20.5525 - val_accuracy: 0.0276\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 17.8816 - val_accuracy: 0.0360\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0344 - accuracy: 0.9889 - val_loss: 16.3553 - val_accuracy: 0.0167\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 18.3712 - val_accuracy: 0.0209\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0273 - accuracy: 0.9883 - val_loss: 19.9386 - val_accuracy: 0.0245\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0289 - accuracy: 0.9913 - val_loss: 18.2453 - val_accuracy: 0.0198\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0378 - accuracy: 0.9855 - val_loss: 16.7472 - val_accuracy: 0.0355\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0460 - accuracy: 0.9841 - val_loss: 13.9582 - val_accuracy: 0.0162\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0439 - accuracy: 0.9844 - val_loss: 15.6755 - val_accuracy: 0.0177\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0332 - accuracy: 0.9876 - val_loss: 17.2595 - val_accuracy: 0.0130\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 18.5071 - val_accuracy: 0.0224\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 20.2387 - val_accuracy: 0.0109\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 20.3676 - val_accuracy: 0.0297\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 18.2637 - val_accuracy: 0.0240\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 16.4249 - val_accuracy: 0.0224\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 19.6667 - val_accuracy: 0.0261\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0304 - accuracy: 0.9879 - val_loss: 21.1243 - val_accuracy: 0.0167\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 20.5343 - val_accuracy: 0.0219\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0263 - accuracy: 0.9900 - val_loss: 20.6906 - val_accuracy: 0.0245\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 14.5376 - val_accuracy: 0.0172\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.0221 - accuracy: 0.9918 - val_loss: 16.3324 - val_accuracy: 0.0167\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 16.1261 - val_accuracy: 0.0172\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 18.8211 - val_accuracy: 0.0266\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0286 - accuracy: 0.9901 - val_loss: 17.4291 - val_accuracy: 0.0266\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 20.8173 - val_accuracy: 0.0276\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 17.5843 - val_accuracy: 0.0089\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0289 - accuracy: 0.9904 - val_loss: 18.0266 - val_accuracy: 0.0120\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 15.4880 - val_accuracy: 0.0167\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 18.1300 - val_accuracy: 0.0052\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 20.7487 - val_accuracy: 0.0193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2746988fb80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(np.array(X_train).astype('float32'), Y_train_categorical, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c9a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba630814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 24ms/step - loss: 5.3409 - accuracy: 0.6044\n",
      "27/27 [==============================] - 1s 6ms/step\n",
      "Test Loss: 5.340921878814697\n",
      "Test Accuracy: 0.6043890714645386\n",
      "Accuracy: 0.6043890865954923\n",
      "F1 Score: 0.5437447255985512\n",
      "Balanced Accuracy: 0.3379712255358807\n",
      "Cohen Kappa Score:\n",
      "0.2352167374411619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "batch_size = 64\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test_categorical))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(\"Cohen Kappa Score:\")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k = cohen_kappa_score(Y_test, predicted_labels, weights='quadratic')\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf79af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3add546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 7s 28ms/step - loss: 0.6653 - accuracy: 0.7061 - val_loss: 16.7211 - val_accuracy: 0.0302\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.4973 - accuracy: 0.7598 - val_loss: 15.1286 - val_accuracy: 0.0370\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 0.4721 - accuracy: 0.7703 - val_loss: 14.2042 - val_accuracy: 0.0193\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.4455 - accuracy: 0.7804 - val_loss: 14.6593 - val_accuracy: 0.0235\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.4228 - accuracy: 0.8015 - val_loss: 13.2441 - val_accuracy: 0.0308\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.4153 - accuracy: 0.8070 - val_loss: 16.0926 - val_accuracy: 0.0219\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.3846 - accuracy: 0.8187 - val_loss: 17.9151 - val_accuracy: 0.0313\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.3426 - accuracy: 0.8461 - val_loss: 13.0558 - val_accuracy: 0.0308\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.3230 - accuracy: 0.8565 - val_loss: 11.0777 - val_accuracy: 0.0130\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.3050 - accuracy: 0.8676 - val_loss: 12.0263 - val_accuracy: 0.0136\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.2972 - accuracy: 0.8740 - val_loss: 12.6804 - val_accuracy: 0.0271\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.2625 - accuracy: 0.8887 - val_loss: 14.1634 - val_accuracy: 0.0250\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.2085 - accuracy: 0.9161 - val_loss: 17.2201 - val_accuracy: 0.0334\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.2102 - accuracy: 0.9151 - val_loss: 18.5090 - val_accuracy: 0.0360\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1715 - accuracy: 0.9344 - val_loss: 15.5666 - val_accuracy: 0.0172\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1392 - accuracy: 0.9472 - val_loss: 15.2212 - val_accuracy: 0.0162\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1929 - accuracy: 0.9241 - val_loss: 15.7248 - val_accuracy: 0.0318\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1386 - accuracy: 0.9502 - val_loss: 25.7762 - val_accuracy: 0.0344\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1402 - accuracy: 0.9480 - val_loss: 13.7937 - val_accuracy: 0.0156\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.1192 - accuracy: 0.9548 - val_loss: 21.1002 - val_accuracy: 0.0292\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.1086 - accuracy: 0.9591 - val_loss: 16.7622 - val_accuracy: 0.0162\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.1038 - accuracy: 0.9635 - val_loss: 18.3910 - val_accuracy: 0.0209\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0839 - accuracy: 0.9704 - val_loss: 16.2948 - val_accuracy: 0.0177\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.0760 - accuracy: 0.9735 - val_loss: 20.5719 - val_accuracy: 0.0276\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 0.0729 - accuracy: 0.9720 - val_loss: 17.6533 - val_accuracy: 0.0287\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0770 - accuracy: 0.9709 - val_loss: 20.1481 - val_accuracy: 0.0141\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0540 - accuracy: 0.9824 - val_loss: 20.5433 - val_accuracy: 0.0214\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0750 - accuracy: 0.9725 - val_loss: 14.5637 - val_accuracy: 0.0125\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0931 - accuracy: 0.9666 - val_loss: 15.5007 - val_accuracy: 0.0162\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0662 - accuracy: 0.9763 - val_loss: 23.1085 - val_accuracy: 0.0370\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0481 - accuracy: 0.9853 - val_loss: 23.1222 - val_accuracy: 0.0334\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.0592 - accuracy: 0.9798 - val_loss: 18.2515 - val_accuracy: 0.0266\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0638 - accuracy: 0.9765 - val_loss: 19.9724 - val_accuracy: 0.0308\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0467 - accuracy: 0.9845 - val_loss: 18.2911 - val_accuracy: 0.0151\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 18.0216 - val_accuracy: 0.0182\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0465 - accuracy: 0.9846 - val_loss: 20.6798 - val_accuracy: 0.0261\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0605 - accuracy: 0.9781 - val_loss: 19.9188 - val_accuracy: 0.0229\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0494 - accuracy: 0.9834 - val_loss: 25.5407 - val_accuracy: 0.0308\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0499 - accuracy: 0.9823 - val_loss: 21.1743 - val_accuracy: 0.0302\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 19.6792 - val_accuracy: 0.0261\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 20.3886 - val_accuracy: 0.0271\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 20.8619 - val_accuracy: 0.0245\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0364 - accuracy: 0.9875 - val_loss: 16.6093 - val_accuracy: 0.0125\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.0583 - accuracy: 0.9794 - val_loss: 18.6476 - val_accuracy: 0.0120\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0471 - accuracy: 0.9831 - val_loss: 17.4763 - val_accuracy: 0.0136\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0342 - accuracy: 0.9876 - val_loss: 19.3705 - val_accuracy: 0.0261\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.0486 - accuracy: 0.9838 - val_loss: 18.2235 - val_accuracy: 0.0245\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.0330 - accuracy: 0.9885 - val_loss: 20.6553 - val_accuracy: 0.0245\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0315 - accuracy: 0.9904 - val_loss: 19.5058 - val_accuracy: 0.0276\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0407 - accuracy: 0.9854 - val_loss: 22.3856 - val_accuracy: 0.0276\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 16.4737 - val_accuracy: 0.0209\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0455 - accuracy: 0.9841 - val_loss: 17.2818 - val_accuracy: 0.0209\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0369 - accuracy: 0.9872 - val_loss: 23.7527 - val_accuracy: 0.0240\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0521 - accuracy: 0.9827 - val_loss: 21.5040 - val_accuracy: 0.0271\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0308 - accuracy: 0.9898 - val_loss: 20.4114 - val_accuracy: 0.0250\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0320 - accuracy: 0.9881 - val_loss: 16.1612 - val_accuracy: 0.0188\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 16.2830 - val_accuracy: 0.0209\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 16.7652 - val_accuracy: 0.0276\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 18.6482 - val_accuracy: 0.0240\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0270 - accuracy: 0.9906 - val_loss: 19.0058 - val_accuracy: 0.0240\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 20.5117 - val_accuracy: 0.0261\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 18.5418 - val_accuracy: 0.0250\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0443 - accuracy: 0.9850 - val_loss: 18.4401 - val_accuracy: 0.0219\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0430 - accuracy: 0.9854 - val_loss: 23.5070 - val_accuracy: 0.0240\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0333 - accuracy: 0.9885 - val_loss: 23.1537 - val_accuracy: 0.0302\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.0296 - accuracy: 0.9898 - val_loss: 17.1211 - val_accuracy: 0.0120\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0377 - accuracy: 0.9883 - val_loss: 22.4875 - val_accuracy: 0.0308\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0263 - accuracy: 0.9906 - val_loss: 19.1582 - val_accuracy: 0.0214\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0264 - accuracy: 0.9904 - val_loss: 16.5762 - val_accuracy: 0.0209\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0306 - accuracy: 0.9897 - val_loss: 17.5719 - val_accuracy: 0.0271\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 18.4929 - val_accuracy: 0.0245\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0333 - accuracy: 0.9875 - val_loss: 18.2193 - val_accuracy: 0.0287\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.0209 - accuracy: 0.9919 - val_loss: 22.7216 - val_accuracy: 0.0083\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0351 - accuracy: 0.9861 - val_loss: 20.8825 - val_accuracy: 0.0250\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 20.4591 - val_accuracy: 0.0214\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 23.8547 - val_accuracy: 0.0229\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 20.2919 - val_accuracy: 0.0151\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 18.2968 - val_accuracy: 0.0235\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 21.0494 - val_accuracy: 0.0209\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 21.9583 - val_accuracy: 0.0250\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 23.4115 - val_accuracy: 0.0334\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 23.3056 - val_accuracy: 0.0245\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 18.5169 - val_accuracy: 0.0271\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0181 - accuracy: 0.9931 - val_loss: 18.9421 - val_accuracy: 0.0235\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 19.3146 - val_accuracy: 0.0193\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 17.5062 - val_accuracy: 0.0271\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0235 - accuracy: 0.9914 - val_loss: 20.8389 - val_accuracy: 0.0250\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 23.2835 - val_accuracy: 0.0302\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0175 - accuracy: 0.9935 - val_loss: 19.6942 - val_accuracy: 0.0167\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 15.3473 - val_accuracy: 0.0177\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 24.2836 - val_accuracy: 0.0349\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0309 - accuracy: 0.9891 - val_loss: 23.2813 - val_accuracy: 0.0313\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 16.1603 - val_accuracy: 0.0240\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 17.4366 - val_accuracy: 0.0229\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 21.4631 - val_accuracy: 0.0261\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 16.9198 - val_accuracy: 0.0287\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 18.7063 - val_accuracy: 0.0177\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0158 - accuracy: 0.9937 - val_loss: 20.6431 - val_accuracy: 0.0172\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 20.4231 - val_accuracy: 0.0125\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0161 - accuracy: 0.9937 - val_loss: 13.8861 - val_accuracy: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2749a39a250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\limuc_mob_32_model.h5\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "# Compile the model\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "new_model.fit(np.array(X_train).astype('float32'), Y_train_categorical, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "394bdf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 17ms/step - loss: 3.8240 - accuracy: 0.5996\n",
      "27/27 [==============================] - 1s 18ms/step\n",
      "Test Loss: 3.823970079421997\n",
      "Test Accuracy: 0.599644124507904\n",
      "Accuracy: 0.599644128113879\n",
      "F1 Score: 0.5201740133923423\n",
      "Balanced Accuracy: 0.3148642823858341\n",
      "Cohen Kappa Score:\n",
      "0.19699459057737745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "batch_size = 64\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test_categorical))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = new_model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(test_dataset)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(\"Cohen Kappa Score:\")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k = cohen_kappa_score(Y_test, predicted_labels, weights='quadratic')\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d9482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a65728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2399a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f8666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
