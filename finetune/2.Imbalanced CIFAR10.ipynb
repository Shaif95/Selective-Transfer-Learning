{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1381389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 10/10 [03:11<00:00, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29009, 32, 32, 3)\n",
      "Y_train shape: (29009,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r\"E:\\imbcifar\\train\"\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_train.append(img_array)\n",
    "            Y_train.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "    \n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e75f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ea81db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 10/10 [00:21<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3222, 32, 32, 3)\n",
      "Y_train shape: (3222,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r\"E:\\imbcifar\\valid\"\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_val = []\n",
    "Y_val = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_val.append(img_array)\n",
    "            Y_val.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "\n",
    "print(f'X_train shape: {X_val.shape}')\n",
    "print(f'Y_train shape: {Y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b1aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "YT = to_categorical(Y_train)\n",
    "VT = to_categorical(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19c7e793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "128b248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 37s 36ms/step - loss: 2.0293 - accuracy: 0.3700 - val_loss: 4.2055 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d0c1fef9a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "num_classes = 10\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights=None, include_top=False, input_shape=(32, 32, 3))    \n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Change units to match the number of classes\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "epochs = 50\n",
    "model.fit(X_train,YT, epochs=epochs,batch_size=32, validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe1492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................................................\n",
      ".......................................................................................\n"
     ]
    }
   ],
   "source": [
    "print(\".......................................................................................\")\n",
    "print(\".......................................................................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57121335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2436374922408442\n",
      "F1 Score: 0.1726247538470893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_val, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_val, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\".......................................................................................\")\n",
    "print(\".......................................................................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2162265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 49s 47ms/step - loss: 1.4081 - accuracy: 0.5989 - val_loss: 1.6674 - val_accuracy: 0.4967\n",
      "Epoch 2/50\n",
      "816/816 [==============================] - 38s 46ms/step - loss: 1.4256 - accuracy: 0.5998 - val_loss: 97.0203 - val_accuracy: 0.0745\n",
      "Epoch 3/50\n",
      "816/816 [==============================] - 41s 51ms/step - loss: 1.1052 - accuracy: 0.6518 - val_loss: 1.9888 - val_accuracy: 0.5495\n",
      "Epoch 4/50\n",
      "816/816 [==============================] - 46s 57ms/step - loss: 0.9994 - accuracy: 0.6898 - val_loss: 1.3359 - val_accuracy: 0.5839\n",
      "Epoch 5/50\n",
      "816/816 [==============================] - 36s 44ms/step - loss: 1.2886 - accuracy: 0.6152 - val_loss: 12.5394 - val_accuracy: 0.0555\n",
      "Epoch 6/50\n",
      "816/816 [==============================] - 39s 48ms/step - loss: 1.1633 - accuracy: 0.6377 - val_loss: 0.5474 - val_accuracy: 0.8156\n",
      "Epoch 7/50\n",
      "816/816 [==============================] - 38s 47ms/step - loss: 0.9144 - accuracy: 0.7087 - val_loss: 0.6116 - val_accuracy: 0.8228\n",
      "Epoch 8/50\n",
      "816/816 [==============================] - 34s 41ms/step - loss: 0.9704 - accuracy: 0.6916 - val_loss: 1.0637 - val_accuracy: 0.5843\n",
      "Epoch 9/50\n",
      "816/816 [==============================] - 34s 42ms/step - loss: 0.7910 - accuracy: 0.7412 - val_loss: 0.6836 - val_accuracy: 0.7473\n",
      "Epoch 10/50\n",
      "816/816 [==============================] - 36s 44ms/step - loss: 0.7869 - accuracy: 0.7437 - val_loss: 0.5810 - val_accuracy: 0.8046\n",
      "Epoch 11/50\n",
      "816/816 [==============================] - 34s 42ms/step - loss: 0.7802 - accuracy: 0.7587 - val_loss: 1.0019 - val_accuracy: 0.6563\n",
      "Epoch 12/50\n",
      "816/816 [==============================] - 37s 46ms/step - loss: 0.6307 - accuracy: 0.7968 - val_loss: 0.6220 - val_accuracy: 0.7835\n",
      "Epoch 13/50\n",
      "816/816 [==============================] - 39s 48ms/step - loss: 0.9543 - accuracy: 0.7121 - val_loss: 3.2528 - val_accuracy: 0.6260\n",
      "Epoch 14/50\n",
      "816/816 [==============================] - 38s 47ms/step - loss: 0.7979 - accuracy: 0.7494 - val_loss: 0.9091 - val_accuracy: 0.6829\n",
      "Epoch 15/50\n",
      "816/816 [==============================] - 34s 42ms/step - loss: 0.5773 - accuracy: 0.8104 - val_loss: 1.0995 - val_accuracy: 0.6911\n",
      "Epoch 16/50\n",
      "816/816 [==============================] - 36s 44ms/step - loss: 0.4923 - accuracy: 0.8407 - val_loss: 0.9245 - val_accuracy: 0.7766\n",
      "Epoch 17/50\n",
      "816/816 [==============================] - 37s 46ms/step - loss: 0.5128 - accuracy: 0.8341 - val_loss: 0.6762 - val_accuracy: 0.7653\n",
      "Epoch 18/50\n",
      "816/816 [==============================] - 35s 42ms/step - loss: 0.4642 - accuracy: 0.8526 - val_loss: 1.7393 - val_accuracy: 0.6132\n",
      "Epoch 19/50\n",
      "816/816 [==============================] - 37s 46ms/step - loss: 0.2981 - accuracy: 0.8993 - val_loss: 1.2629 - val_accuracy: 0.6839\n",
      "Epoch 20/50\n",
      "816/816 [==============================] - 39s 48ms/step - loss: 0.2262 - accuracy: 0.9238 - val_loss: 0.9478 - val_accuracy: 0.7318\n",
      "Epoch 21/50\n",
      "816/816 [==============================] - 38s 46ms/step - loss: 0.4176 - accuracy: 0.8794 - val_loss: 3.0601 - val_accuracy: 0.5064\n",
      "Epoch 22/50\n",
      "816/816 [==============================] - 38s 46ms/step - loss: 0.2795 - accuracy: 0.9069 - val_loss: 1.6931 - val_accuracy: 0.5684\n",
      "Epoch 23/50\n",
      "816/816 [==============================] - 44s 54ms/step - loss: 0.1460 - accuracy: 0.9512 - val_loss: 1.5288 - val_accuracy: 0.6805\n",
      "Epoch 24/50\n",
      "816/816 [==============================] - 38s 46ms/step - loss: 0.1263 - accuracy: 0.9569 - val_loss: 1.0604 - val_accuracy: 0.7766\n",
      "Epoch 25/50\n",
      "816/816 [==============================] - 36s 44ms/step - loss: 0.1476 - accuracy: 0.9505 - val_loss: 0.8835 - val_accuracy: 0.8145\n",
      "Epoch 26/50\n",
      "816/816 [==============================] - 38s 46ms/step - loss: 0.1205 - accuracy: 0.9593 - val_loss: 0.6994 - val_accuracy: 0.8245\n",
      "Epoch 27/50\n",
      "816/816 [==============================] - 35s 43ms/step - loss: 0.1104 - accuracy: 0.9625 - val_loss: 2.1383 - val_accuracy: 0.5981\n",
      "Epoch 28/50\n",
      "816/816 [==============================] - 35s 43ms/step - loss: 0.1628 - accuracy: 0.9486 - val_loss: 2.5575 - val_accuracy: 0.5522\n",
      "Epoch 29/50\n",
      "816/816 [==============================] - 39s 48ms/step - loss: 0.1042 - accuracy: 0.9659 - val_loss: 1.8000 - val_accuracy: 0.6325\n",
      "Epoch 30/50\n",
      "816/816 [==============================] - 38s 46ms/step - loss: 0.0653 - accuracy: 0.9781 - val_loss: 2.0567 - val_accuracy: 0.6294\n",
      "Epoch 31/50\n",
      "816/816 [==============================] - 35s 43ms/step - loss: 0.0704 - accuracy: 0.9752 - val_loss: 1.5708 - val_accuracy: 0.6949\n",
      "Epoch 32/50\n",
      "816/816 [==============================] - 47s 57ms/step - loss: 0.0827 - accuracy: 0.9710 - val_loss: 1.2760 - val_accuracy: 0.7491\n",
      "Epoch 33/50\n",
      "816/816 [==============================] - 35s 43ms/step - loss: 0.0694 - accuracy: 0.9774 - val_loss: 1.4084 - val_accuracy: 0.7191\n",
      "Epoch 34/50\n",
      "816/816 [==============================] - 32s 39ms/step - loss: 0.0773 - accuracy: 0.9751 - val_loss: 1.0429 - val_accuracy: 0.7666\n",
      "Epoch 35/50\n",
      "816/816 [==============================] - 31s 38ms/step - loss: 0.4428 - accuracy: 0.8686 - val_loss: 1.1580 - val_accuracy: 0.7122\n",
      "Epoch 36/50\n",
      "816/816 [==============================] - 33s 41ms/step - loss: 0.0947 - accuracy: 0.9709 - val_loss: 1.1029 - val_accuracy: 0.7266\n",
      "Epoch 37/50\n",
      "816/816 [==============================] - 31s 38ms/step - loss: 0.1193 - accuracy: 0.9648 - val_loss: 0.8389 - val_accuracy: 0.8204\n",
      "Epoch 38/50\n",
      "816/816 [==============================] - 30s 37ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 1.3706 - val_accuracy: 0.7277\n",
      "Epoch 39/50\n",
      "816/816 [==============================] - 32s 40ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 1.8208 - val_accuracy: 0.6649\n",
      "Epoch 40/50\n",
      "816/816 [==============================] - 32s 39ms/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 1.1189 - val_accuracy: 0.7925\n",
      "Epoch 41/50\n",
      "816/816 [==============================] - 37s 46ms/step - loss: 0.0552 - accuracy: 0.9805 - val_loss: 2.3027 - val_accuracy: 0.6143\n",
      "Epoch 42/50\n",
      "816/816 [==============================] - 36s 45ms/step - loss: 0.0826 - accuracy: 0.9732 - val_loss: 1.4379 - val_accuracy: 0.7308\n",
      "Epoch 43/50\n",
      "816/816 [==============================] - 38s 47ms/step - loss: 0.0490 - accuracy: 0.9853 - val_loss: 2.0250 - val_accuracy: 0.6687\n",
      "Epoch 44/50\n",
      "816/816 [==============================] - 40s 49ms/step - loss: 0.0560 - accuracy: 0.9817 - val_loss: 2.5239 - val_accuracy: 0.5836\n",
      "Epoch 45/50\n",
      "816/816 [==============================] - 41s 51ms/step - loss: 0.0472 - accuracy: 0.9843 - val_loss: 1.4641 - val_accuracy: 0.7573\n",
      "Epoch 46/50\n",
      "816/816 [==============================] - 46s 56ms/step - loss: 0.0624 - accuracy: 0.9797 - val_loss: 1.5394 - val_accuracy: 0.7349\n",
      "Epoch 47/50\n",
      "816/816 [==============================] - 39s 48ms/step - loss: 0.0667 - accuracy: 0.9785 - val_loss: 1.3840 - val_accuracy: 0.7091\n",
      "Epoch 48/50\n",
      "816/816 [==============================] - 39s 47ms/step - loss: 0.0669 - accuracy: 0.9807 - val_loss: 1.1346 - val_accuracy: 0.7828\n",
      "Epoch 49/50\n",
      "816/816 [==============================] - 41s 50ms/step - loss: 0.0565 - accuracy: 0.9817 - val_loss: 2.1172 - val_accuracy: 0.6484\n",
      "Epoch 50/50\n",
      "816/816 [==============================] - 39s 48ms/step - loss: 0.0310 - accuracy: 0.9898 - val_loss: 3.4577 - val_accuracy: 0.4836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2636b56a340>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "num_classes = 10\n",
    "model = tensorflow.keras.models.load_model(r\"D:\\lbp_imbcifar_model.h5\")\n",
    "\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D(keepdims=False)(x)  # Explicitly specify keepdims\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "new_model = tensorflow.keras.models.Model(inputs=model.input, outputs=output) \n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "epochs = 50\n",
    "new_model.fit(X_train,YT, epochs=epochs,batch_size=32, validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c7b3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "816/816 [==============================] - 40s 49ms/step - loss: 0.0370 - accuracy: 0.9876 - val_loss: 3.4687 - val_accuracy: 0.5198\n",
      "Epoch 2/2\n",
      "816/816 [==============================] - 37s 45ms/step - loss: 0.0356 - accuracy: 0.9883 - val_loss: 2.4139 - val_accuracy: 0.6329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2672afe25b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(X_train,YT, epochs=2,batch_size=32, validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46296b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7507759155803848\n",
      "F1 Score: 0.74997179736704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_val, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_val, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c96a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\".......................................................................................\")\n",
    "print(\".......................................................................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34859ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e95e57aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/50\n",
      "363/363 [==============================] - 42s 68ms/step - loss: 516.2614 - accuracy: 0.1743 - val_loss: 4347.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 21s 58ms/step - loss: 193.0619 - accuracy: 0.1802 - val_loss: 2157.3953 - val_accuracy: 0.0109\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 22s 61ms/step - loss: 62.5039 - accuracy: 0.1754 - val_loss: 1404.2903 - val_accuracy: 0.1643\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 23s 63ms/step - loss: 34.9450 - accuracy: 0.1793 - val_loss: 934.8641 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 20s 56ms/step - loss: 20.3900 - accuracy: 0.1827 - val_loss: 715.6703 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 22s 61ms/step - loss: 15.4835 - accuracy: 0.1938 - val_loss: 586.2610 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 23s 65ms/step - loss: 12.3891 - accuracy: 0.2007 - val_loss: 405.6440 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 23s 63ms/step - loss: 10.8610 - accuracy: 0.2106 - val_loss: 354.6766 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 24s 67ms/step - loss: 9.7738 - accuracy: 0.2126 - val_loss: 303.3064 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 21s 58ms/step - loss: 8.8840 - accuracy: 0.2166 - val_loss: 299.3788 - val_accuracy: 1.7235e-04\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 22s 61ms/step - loss: 8.6963 - accuracy: 0.2234 - val_loss: 280.6729 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 21s 59ms/step - loss: 7.8841 - accuracy: 0.2225 - val_loss: 249.9208 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 20s 56ms/step - loss: 6.7834 - accuracy: 0.2280 - val_loss: 232.1834 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 24s 67ms/step - loss: 6.1913 - accuracy: 0.2360 - val_loss: 202.2316 - val_accuracy: 3.4471e-04\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 21s 58ms/step - loss: 5.8539 - accuracy: 0.2414 - val_loss: 189.8287 - val_accuracy: 0.1081\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 22s 61ms/step - loss: 5.2689 - accuracy: 0.2459 - val_loss: 166.7606 - val_accuracy: 0.0029\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 22s 60ms/step - loss: 4.6999 - accuracy: 0.2483 - val_loss: 161.6738 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 22s 60ms/step - loss: 4.9571 - accuracy: 0.2511 - val_loss: 141.6791 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 23s 64ms/step - loss: 5.2777 - accuracy: 0.2445 - val_loss: 119.6050 - val_accuracy: 0.0128\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 23s 64ms/step - loss: 4.2584 - accuracy: 0.2519 - val_loss: 120.8061 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 21s 58ms/step - loss: 3.9708 - accuracy: 0.2634 - val_loss: 94.2480 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 21s 58ms/step - loss: 4.1719 - accuracy: 0.2542 - val_loss: 119.0267 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 22s 59ms/step - loss: 4.2263 - accuracy: 0.2557 - val_loss: 85.6582 - val_accuracy: 0.0016\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 21s 57ms/step - loss: 3.0151 - accuracy: 0.2717 - val_loss: 85.3932 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 22s 62ms/step - loss: 3.0341 - accuracy: 0.2735 - val_loss: 76.3234 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 22s 60ms/step - loss: 3.1201 - accuracy: 0.2771 - val_loss: 81.1580 - val_accuracy: 0.0733\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 22s 60ms/step - loss: 2.9204 - accuracy: 0.2781 - val_loss: 74.8186 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 21s 57ms/step - loss: 2.6993 - accuracy: 0.2819 - val_loss: 55.3937 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 22s 60ms/step - loss: 2.8404 - accuracy: 0.2803 - val_loss: 45.4400 - val_accuracy: 0.0403\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 23s 65ms/step - loss: 2.4638 - accuracy: 0.2966 - val_loss: 46.2611 - val_accuracy: 0.0805\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 23s 62ms/step - loss: 2.4525 - accuracy: 0.2965 - val_loss: 65.6701 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 21s 58ms/step - loss: 2.4663 - accuracy: 0.2944 - val_loss: 33.8688 - val_accuracy: 0.0090\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 22s 62ms/step - loss: 2.1426 - accuracy: 0.3132 - val_loss: 20.9173 - val_accuracy: 0.0074\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 21s 58ms/step - loss: 2.1536 - accuracy: 0.3150 - val_loss: 27.6868 - val_accuracy: 0.0684\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 19s 52ms/step - loss: 2.0793 - accuracy: 0.3282 - val_loss: 36.6038 - val_accuracy: 1.7235e-04\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 24s 65ms/step - loss: 1.9870 - accuracy: 0.3361 - val_loss: 30.5608 - val_accuracy: 8.6177e-04\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 22s 59ms/step - loss: 3.1389 - accuracy: 0.3029 - val_loss: 95.7763 - val_accuracy: 0.0028\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 20s 55ms/step - loss: 1.9031 - accuracy: 0.3317 - val_loss: 52.8539 - val_accuracy: 0.0179\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 20s 56ms/step - loss: 1.9114 - accuracy: 0.3409 - val_loss: 47.5003 - val_accuracy: 0.0036\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 22s 59ms/step - loss: 1.8136 - accuracy: 0.3519 - val_loss: 37.1911 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 24s 65ms/step - loss: 1.8291 - accuracy: 0.3514 - val_loss: 44.2472 - val_accuracy: 3.4471e-04\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 23s 62ms/step - loss: 1.8563 - accuracy: 0.3428 - val_loss: 29.0198 - val_accuracy: 0.0505\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 21s 59ms/step - loss: 1.8188 - accuracy: 0.3561 - val_loss: 33.1546 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 21s 58ms/step - loss: 1.8996 - accuracy: 0.3453 - val_loss: 14.1266 - val_accuracy: 0.0036\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 21s 59ms/step - loss: 2.1184 - accuracy: 0.3414 - val_loss: 291.8795 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 21s 57ms/step - loss: 5.7001 - accuracy: 0.2785 - val_loss: 51.7829 - val_accuracy: 0.0057\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 24s 65ms/step - loss: 1.8020 - accuracy: 0.3641 - val_loss: 38.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 23s 63ms/step - loss: 2.4314 - accuracy: 0.3252 - val_loss: 61.9072 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 21s 58ms/step - loss: 1.7687 - accuracy: 0.3584 - val_loss: 44.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 20s 56ms/step - loss: 1.7992 - accuracy: 0.3538 - val_loss: 69.6093 - val_accuracy: 0.0376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de895e95e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    \n",
    "num_classes = 10  \n",
    "model = keras.models.load_model(r\"C:\\Users\\shaif\\Downloads\\imb_ssl.h5\")\n",
    "x = model.layers[-8].output  \n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "new_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model.fit(X_train, YT, batch_size=64, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a042bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fca0bb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'V_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, f1_score\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming you have trained a model and obtained predicted probabilities on x_test\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m new_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mV_val\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert predicted probabilities to predicted labels\u001b[39;00m\n\u001b[0;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'V_val' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = new_model.predict(V_val)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddafe43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\".......................................................................................\")\n",
    "print(\".......................................................................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fcc5f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "816/816 [==============================] - 53s 58ms/step - loss: 2.5850 - accuracy: 0.2441 - val_loss: 158.5921 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "816/816 [==============================] - 41s 50ms/step - loss: 2.8767 - accuracy: 0.2143 - val_loss: 7.1132 - val_accuracy: 0.0203\n",
      "Epoch 3/50\n",
      "816/816 [==============================] - 43s 53ms/step - loss: 2.8043 - accuracy: 0.2048 - val_loss: 6.1752 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "816/816 [==============================] - 41s 50ms/step - loss: 2.4426 - accuracy: 0.2142 - val_loss: 2.1708 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "816/816 [==============================] - 45s 55ms/step - loss: 2.6414 - accuracy: 0.2291 - val_loss: 2.7501 - val_accuracy: 0.0052\n",
      "Epoch 6/50\n",
      "816/816 [==============================] - 46s 57ms/step - loss: 2.2906 - accuracy: 0.2515 - val_loss: 111.9835 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "816/816 [==============================] - 46s 56ms/step - loss: 2.4185 - accuracy: 0.2004 - val_loss: 5.5025 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "816/816 [==============================] - 45s 55ms/step - loss: 2.1857 - accuracy: 0.2533 - val_loss: 3.2060 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "816/816 [==============================] - 46s 57ms/step - loss: 2.2150 - accuracy: 0.3007 - val_loss: 3.2842 - val_accuracy: 0.1217\n",
      "Epoch 10/50\n",
      "816/816 [==============================] - 45s 56ms/step - loss: 1.9209 - accuracy: 0.3484 - val_loss: 5.1003 - val_accuracy: 0.0869\n",
      "Epoch 11/50\n",
      "816/816 [==============================] - 49s 61ms/step - loss: 1.9087 - accuracy: 0.3796 - val_loss: 8.1636 - val_accuracy: 0.1034\n",
      "Epoch 12/50\n",
      "816/816 [==============================] - 53s 65ms/step - loss: 1.8111 - accuracy: 0.3983 - val_loss: 4.2053 - val_accuracy: 0.0052\n",
      "Epoch 13/50\n",
      "816/816 [==============================] - 53s 65ms/step - loss: 2.0293 - accuracy: 0.3272 - val_loss: 1.9198 - val_accuracy: 0.1796\n",
      "Epoch 14/50\n",
      "816/816 [==============================] - 51s 62ms/step - loss: 1.9220 - accuracy: 0.4001 - val_loss: 1.8771 - val_accuracy: 0.1017\n",
      "Epoch 15/50\n",
      "816/816 [==============================] - 46s 57ms/step - loss: 1.8133 - accuracy: 0.3903 - val_loss: 111.2189 - val_accuracy: 0.0672\n",
      "Epoch 16/50\n",
      "816/816 [==============================] - 44s 54ms/step - loss: 1.8275 - accuracy: 0.4117 - val_loss: 2.3550 - val_accuracy: 0.0896\n",
      "Epoch 17/50\n",
      "816/816 [==============================] - 48s 59ms/step - loss: 1.7438 - accuracy: 0.4353 - val_loss: 2.3385 - val_accuracy: 0.1189\n",
      "Epoch 18/50\n",
      "816/816 [==============================] - 49s 60ms/step - loss: 1.7075 - accuracy: 0.4232 - val_loss: 2.2620 - val_accuracy: 0.1927\n",
      "Epoch 19/50\n",
      "816/816 [==============================] - 61s 74ms/step - loss: 1.7171 - accuracy: 0.4378 - val_loss: 2.6558 - val_accuracy: 0.0948\n",
      "Epoch 20/50\n",
      "816/816 [==============================] - 67s 83ms/step - loss: 1.5855 - accuracy: 0.4452 - val_loss: 2.6449 - val_accuracy: 0.1765\n",
      "Epoch 21/50\n",
      "816/816 [==============================] - 65s 80ms/step - loss: 1.5204 - accuracy: 0.4704 - val_loss: 1.9666 - val_accuracy: 0.2706\n",
      "Epoch 22/50\n",
      "816/816 [==============================] - 72s 88ms/step - loss: 1.5044 - accuracy: 0.4684 - val_loss: 2.5204 - val_accuracy: 0.2330\n",
      "Epoch 23/50\n",
      "816/816 [==============================] - 70s 86ms/step - loss: 1.5469 - accuracy: 0.4682 - val_loss: 26.6114 - val_accuracy: 0.0531\n",
      "Epoch 24/50\n",
      "816/816 [==============================] - 74s 90ms/step - loss: 1.7138 - accuracy: 0.4147 - val_loss: 2.8107 - val_accuracy: 0.0531\n",
      "Epoch 25/50\n",
      "816/816 [==============================] - 75s 92ms/step - loss: 1.4990 - accuracy: 0.4836 - val_loss: 2.2235 - val_accuracy: 0.2647\n",
      "Epoch 26/50\n",
      "816/816 [==============================] - 73s 90ms/step - loss: 1.3902 - accuracy: 0.5141 - val_loss: 2.0350 - val_accuracy: 0.2582\n",
      "Epoch 27/50\n",
      "816/816 [==============================] - 73s 89ms/step - loss: 1.2996 - accuracy: 0.5450 - val_loss: 1.7262 - val_accuracy: 0.4226\n",
      "Epoch 28/50\n",
      "816/816 [==============================] - 73s 90ms/step - loss: 1.2809 - accuracy: 0.5467 - val_loss: 1.5837 - val_accuracy: 0.3957\n",
      "Epoch 29/50\n",
      "816/816 [==============================] - 75s 92ms/step - loss: 1.1984 - accuracy: 0.5708 - val_loss: 1.9795 - val_accuracy: 0.3737\n",
      "Epoch 30/50\n",
      "816/816 [==============================] - 71s 88ms/step - loss: 1.1675 - accuracy: 0.5816 - val_loss: 1.7966 - val_accuracy: 0.2437\n",
      "Epoch 31/50\n",
      "816/816 [==============================] - 74s 90ms/step - loss: 1.1096 - accuracy: 0.6024 - val_loss: 2.0811 - val_accuracy: 0.2485\n",
      "Epoch 32/50\n",
      "816/816 [==============================] - 75s 92ms/step - loss: 1.0408 - accuracy: 0.6216 - val_loss: 1.6013 - val_accuracy: 0.3909\n",
      "Epoch 33/50\n",
      "816/816 [==============================] - 72s 88ms/step - loss: 0.9957 - accuracy: 0.6375 - val_loss: 1.5009 - val_accuracy: 0.3992\n",
      "Epoch 34/50\n",
      "816/816 [==============================] - 72s 88ms/step - loss: 0.9088 - accuracy: 0.6601 - val_loss: 1.4382 - val_accuracy: 0.4822\n",
      "Epoch 35/50\n",
      "816/816 [==============================] - 57s 70ms/step - loss: 0.8693 - accuracy: 0.6815 - val_loss: 2.9324 - val_accuracy: 0.0745\n",
      "Epoch 36/50\n",
      "816/816 [==============================] - 53s 65ms/step - loss: 0.8292 - accuracy: 0.6922 - val_loss: 1.5557 - val_accuracy: 0.4681\n",
      "Epoch 37/50\n",
      "816/816 [==============================] - 57s 70ms/step - loss: 0.7754 - accuracy: 0.7117 - val_loss: 2.9850 - val_accuracy: 0.2137\n",
      "Epoch 38/50\n",
      "372/816 [============>.................] - ETA: 30s - loss: 0.8198 - accuracy: 0.6977"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "num_classes = 10\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights=None, include_top=False, input_shape=(32, 32, 3))    \n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Change units to match the number of classes\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "epochs = 50\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Assuming Y_train is the non-categorical labels\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(Y_train), y=Y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Convert Y_train to categorical labels\n",
    "Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "\n",
    "# Train the model with class weights\n",
    "model.fit(X_train, Y_train_categorical, \n",
    "          epochs=epochs, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          class_weight=class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba24554",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\".......................................................................................\")\n",
    "print(\".......................................................................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73589b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_val, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_val, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050164ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579aabda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Load the pre-trained SimCLR model\n",
    "simclr_model = load_model(r'C:\\Users\\shaif\\Downloads\\imb_ssl.h5')\n",
    "\n",
    "# Extract the input and output from one branch of the SimCLR model\n",
    "base_input = simclr_model.input[0]  # Input from the first branch\n",
    "base_output = simclr_model.get_layer(\"global_average_pooling2d\").output  # Output before projection head of the first branch\n",
    "\n",
    "# Create a new model using the extracted backbone\n",
    "backbone_model = Model(inputs=base_input, outputs=base_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d5a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_model(backbone_model, num_classes=10):\n",
    "    # Add a classification head\n",
    "    x = layers.Dense(256, activation='relu')(backbone_model.output)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    classification_output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Build the new model\n",
    "    classification_model = Model(inputs=backbone_model.input, outputs=classification_output)\n",
    "\n",
    "    return classification_model\n",
    "\n",
    "# Create the classification model\n",
    "classification_model = create_classification_model(backbone_model)\n",
    "#classification_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94f66e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 19s 87ms/step - loss: 2.4014 - accuracy: 0.2483 - val_loss: 6.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 5s 57ms/step - loss: 1.8952 - accuracy: 0.3630 - val_loss: 5.6708 - val_accuracy: 1.7235e-04\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 6s 62ms/step - loss: 1.7261 - accuracy: 0.4059 - val_loss: 5.6247 - val_accuracy: 6.8942e-04\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: 1.6259 - accuracy: 0.4331 - val_loss: 5.7996 - val_accuracy: 0.0012\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 1.5723 - accuracy: 0.4512 - val_loss: 5.8469 - val_accuracy: 0.0028\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 1.5069 - accuracy: 0.4709 - val_loss: 5.9883 - val_accuracy: 0.0031\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 5s 59ms/step - loss: 1.4585 - accuracy: 0.4900 - val_loss: 6.1568 - val_accuracy: 0.0031\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: 1.4174 - accuracy: 0.5030 - val_loss: 6.2346 - val_accuracy: 0.0048\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 6s 62ms/step - loss: 1.3791 - accuracy: 0.5182 - val_loss: 6.3905 - val_accuracy: 0.0055\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 5s 59ms/step - loss: 1.3452 - accuracy: 0.5279 - val_loss: 6.4915 - val_accuracy: 0.0109\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: 1.3094 - accuracy: 0.5416 - val_loss: 6.6197 - val_accuracy: 0.0091\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: 1.2795 - accuracy: 0.5505 - val_loss: 6.7273 - val_accuracy: 0.0148\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 1.2535 - accuracy: 0.5615 - val_loss: 6.8334 - val_accuracy: 0.0176\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 5s 59ms/step - loss: 1.2123 - accuracy: 0.5753 - val_loss: 7.0331 - val_accuracy: 0.0188\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 1.1893 - accuracy: 0.5832 - val_loss: 7.2094 - val_accuracy: 0.0188\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 6s 64ms/step - loss: 1.1624 - accuracy: 0.5934 - val_loss: 7.2881 - val_accuracy: 0.0207\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 1.1365 - accuracy: 0.6034 - val_loss: 7.2775 - val_accuracy: 0.0284\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 6s 65ms/step - loss: 1.1131 - accuracy: 0.6086 - val_loss: 7.3821 - val_accuracy: 0.0312\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 6s 65ms/step - loss: 1.0828 - accuracy: 0.6181 - val_loss: 7.5525 - val_accuracy: 0.0327\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 6s 66ms/step - loss: 1.0615 - accuracy: 0.6251 - val_loss: 7.6455 - val_accuracy: 0.0383\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 1.0361 - accuracy: 0.6364 - val_loss: 7.7626 - val_accuracy: 0.0405\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 6s 67ms/step - loss: 1.0154 - accuracy: 0.6452 - val_loss: 7.9540 - val_accuracy: 0.0434\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 0.9854 - accuracy: 0.6534 - val_loss: 7.8839 - val_accuracy: 0.0489\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: 0.9655 - accuracy: 0.6605 - val_loss: 8.1012 - val_accuracy: 0.0419\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: 0.9364 - accuracy: 0.6698 - val_loss: 8.3062 - val_accuracy: 0.0467\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 0.9224 - accuracy: 0.6770 - val_loss: 8.3915 - val_accuracy: 0.0545\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 0.8955 - accuracy: 0.6822 - val_loss: 8.5936 - val_accuracy: 0.0457\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 0.8780 - accuracy: 0.6899 - val_loss: 8.4656 - val_accuracy: 0.0593\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 6s 63ms/step - loss: 0.8507 - accuracy: 0.7016 - val_loss: 8.8785 - val_accuracy: 0.0662\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: 0.8336 - accuracy: 0.7098 - val_loss: 8.9005 - val_accuracy: 0.0512\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 6s 64ms/step - loss: 0.8119 - accuracy: 0.7139 - val_loss: 8.8720 - val_accuracy: 0.0598\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 6s 62ms/step - loss: 0.7959 - accuracy: 0.7205 - val_loss: 8.9600 - val_accuracy: 0.0757\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 0.7670 - accuracy: 0.7306 - val_loss: 9.2617 - val_accuracy: 0.0755\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 6s 61ms/step - loss: 0.7547 - accuracy: 0.7343 - val_loss: 9.5762 - val_accuracy: 0.0705\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 6s 65ms/step - loss: 0.7305 - accuracy: 0.7412 - val_loss: 9.5479 - val_accuracy: 0.0765\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: 0.7072 - accuracy: 0.7512 - val_loss: 9.6108 - val_accuracy: 0.0776\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 6s 63ms/step - loss: 0.6862 - accuracy: 0.7586 - val_loss: 9.6229 - val_accuracy: 0.0788\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 6s 63ms/step - loss: 0.6678 - accuracy: 0.7645 - val_loss: 9.9371 - val_accuracy: 0.0800\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 6s 64ms/step - loss: 0.6562 - accuracy: 0.7709 - val_loss: 9.9450 - val_accuracy: 0.0815\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 6s 63ms/step - loss: 0.6322 - accuracy: 0.7785 - val_loss: 10.3938 - val_accuracy: 0.0748\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 5s 59ms/step - loss: 0.6163 - accuracy: 0.7829 - val_loss: 10.4432 - val_accuracy: 0.0765\n",
      "Epoch 42/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: 0.6011 - accuracy: 0.7865 - val_loss: 10.6809 - val_accuracy: 0.0881\n",
      "Epoch 43/50\n",
      "91/91 [==============================] - 6s 63ms/step - loss: 0.5845 - accuracy: 0.7952 - val_loss: 10.7238 - val_accuracy: 0.0846\n",
      "Epoch 44/50\n",
      "91/91 [==============================] - 6s 62ms/step - loss: 0.5585 - accuracy: 0.8064 - val_loss: 10.8273 - val_accuracy: 0.0879\n",
      "Epoch 45/50\n",
      "91/91 [==============================] - 6s 63ms/step - loss: 0.5440 - accuracy: 0.8088 - val_loss: 10.9686 - val_accuracy: 0.0972\n",
      "Epoch 46/50\n",
      "91/91 [==============================] - 6s 63ms/step - loss: 0.5254 - accuracy: 0.8149 - val_loss: 11.3986 - val_accuracy: 0.0924\n",
      "Epoch 47/50\n",
      "91/91 [==============================] - 6s 64ms/step - loss: 0.5124 - accuracy: 0.8194 - val_loss: 11.7671 - val_accuracy: 0.0848\n",
      "Epoch 48/50\n",
      "91/91 [==============================] - 6s 62ms/step - loss: 0.5012 - accuracy: 0.8252 - val_loss: 11.4175 - val_accuracy: 0.0962\n",
      "Epoch 49/50\n",
      "91/91 [==============================] - 6s 63ms/step - loss: 0.4829 - accuracy: 0.8306 - val_loss: 11.6596 - val_accuracy: 0.1036\n",
      "Epoch 50/50\n",
      "91/91 [==============================] - 6s 62ms/step - loss: 0.4705 - accuracy: 0.8326 - val_loss: 11.9275 - val_accuracy: 0.0945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a7137c6c70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the classification model\n",
    "classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                             loss='sparse_categorical_crossentropy',\n",
    "                             metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model using the labeled dataset\n",
    "classification_model.fit(X_train, Y_train, batch_size=256, epochs=50, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3da1438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 3s 23ms/step - loss: 3.3872 - accuracy: 0.5413\n",
      "Test Accuracy: 54.13%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classification model on the test set\n",
    "test_loss, test_accuracy = classification_model.evaluate(X_val, Y_val)\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7879a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a485b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d8bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
