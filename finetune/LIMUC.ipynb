{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14666713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (9590, 32, 32, 3)\n",
      "Shape of Y_train_categorical: (9590, 4)\n",
      "Shape of X_test: (1686, 32, 32, 3)\n",
      "Shape of Y_test_categorical: (1686, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the paths to your dataset folders\n",
    "train_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\train_and_validation_sets\\train_and_validation_sets\"\n",
    "test_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\test_set\\test_set\"\n",
    "\n",
    "# Initialize empty lists for X_train, Y_train, X_test, and Y_test\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "# Initialize an empty list to store categorical labels\n",
    "categorical_labels = []\n",
    "\n",
    "# Define a function to read and preprocess images\n",
    "def process_images(folder_path, label, is_train_set=True):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path) and filename.endswith(\".bmp\"):  # Check if it's a file and ends with .bmp\n",
    "            # Open and resize the image to (32, 32, 3)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((32, 32))\n",
    "            img = img.convert(\"RGB\")\n",
    "            \n",
    "            # Convert image data to a NumPy array\n",
    "            img_array = np.array(img).astype('float32')  # Convert to float\n",
    "            \n",
    "            # Normalize the image data (optional)\n",
    "            img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "            \n",
    "            # Append the image data to the appropriate list\n",
    "            if is_train_set:\n",
    "                X_train.append(img_array)\n",
    "                Y_train.append(label)  # Append the numerical label\n",
    "            else:\n",
    "                X_test.append(img_array)\n",
    "                Y_test.append(label)  # Append the numerical label\n",
    "            \n",
    "            # Append the label for categorical encoding\n",
    "            categorical_labels.append(label)  # Append the numerical label\n",
    "\n",
    "# List the folders inside the training dataset directory\n",
    "train_folders = os.listdir(train_dataset_dir)\n",
    "\n",
    "# Create a label encoder for categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Loop through the training folders and process images\n",
    "for label, folder_name in enumerate(train_folders):\n",
    "    folder_path = os.path.join(train_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label)\n",
    "\n",
    "# List the folders inside the test dataset directory\n",
    "test_folders = os.listdir(test_dataset_dir)\n",
    "\n",
    "# Loop through the test folders and process images\n",
    "for label, folder_name in enumerate(test_folders):\n",
    "    folder_path = os.path.join(test_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label, is_train_set=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# Encode Y_train and Y_test categorically\n",
    "num_classes = len(np.unique(categorical_labels))\n",
    "  # Update this to match the number of classes\n",
    "\n",
    "# Convert Y_train and Y_test to NumPy arrays\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Make sure your labels are integers ranging from 0 to num_classes - 1\n",
    "Y_train = Y_train.astype(int)\n",
    "Y_test = Y_test.astype(int)\n",
    "\n",
    "# One-hot encode the labels\n",
    "Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "Y_test_categorical = to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# # Encode Y_train and Y_test categorically using the label encoder\n",
    "# num_classes = len(np.unique(Y_train))  # Automatically determine the number of classes\n",
    "# Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "# Y_test_categorical = to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# Check the shape of X_train, Y_train_categorical, X_test, and Y_test_categorical\n",
    "print(\"Shape of X_train:\", np.shape(X_train))\n",
    "print(\"Shape of Y_train_categorical:\", np.shape(Y_train_categorical))\n",
    "print(\"Shape of X_test:\", np.shape(X_test))\n",
    "print(\"Shape of Y_test_categorical:\", np.shape(Y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4596ee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mayo 0', 'Mayo 1', 'Mayo 2', 'Mayo 3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96837b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1def5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_1.00_224 (Functio  (None, 1, 1, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1024)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 4100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,232,964\n",
      "Trainable params: 3,211,076\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "#base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "base_model = MobileNet(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Change units to match the number of classes\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e7cde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 7s 29ms/step - loss: 0.9070 - accuracy: 0.6794 - val_loss: 31.6965 - val_accuracy: 5.2138e-04\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.5385 - accuracy: 0.7466 - val_loss: 20.5966 - val_accuracy: 0.0010\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.5013 - accuracy: 0.7663 - val_loss: 11.8314 - val_accuracy: 5.2138e-04\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4813 - accuracy: 0.7763 - val_loss: 13.0816 - val_accuracy: 0.0162\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4621 - accuracy: 0.7871 - val_loss: 13.4982 - val_accuracy: 0.0193\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.4311 - accuracy: 0.8012 - val_loss: 12.1383 - val_accuracy: 0.0334\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.4227 - accuracy: 0.8127 - val_loss: 11.8250 - val_accuracy: 0.0240\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.4182 - accuracy: 0.8130 - val_loss: 11.0826 - val_accuracy: 0.0328\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3644 - accuracy: 0.8393 - val_loss: 11.0365 - val_accuracy: 0.0266\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.3478 - accuracy: 0.8489 - val_loss: 12.3180 - val_accuracy: 0.0266\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3054 - accuracy: 0.8673 - val_loss: 13.4113 - val_accuracy: 0.0266\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2752 - accuracy: 0.8790 - val_loss: 12.5692 - val_accuracy: 0.0177\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.2451 - accuracy: 0.9000 - val_loss: 13.1232 - val_accuracy: 0.0266\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.2251 - accuracy: 0.9086 - val_loss: 12.5525 - val_accuracy: 0.0287\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.2096 - accuracy: 0.9162 - val_loss: 12.8293 - val_accuracy: 0.0302\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1883 - accuracy: 0.9251 - val_loss: 12.3872 - val_accuracy: 0.0235\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.1892 - accuracy: 0.9254 - val_loss: 12.1923 - val_accuracy: 0.0156\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.1668 - accuracy: 0.9372 - val_loss: 13.2835 - val_accuracy: 0.0323\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.1518 - accuracy: 0.9424 - val_loss: 12.2342 - val_accuracy: 0.0094\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.1468 - accuracy: 0.9446 - val_loss: 14.3116 - val_accuracy: 0.0308\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1225 - accuracy: 0.9540 - val_loss: 14.5182 - val_accuracy: 0.0167\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.1416 - accuracy: 0.9445 - val_loss: 12.8871 - val_accuracy: 0.0287\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1165 - accuracy: 0.9593 - val_loss: 13.2107 - val_accuracy: 0.0177\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1191 - accuracy: 0.9567 - val_loss: 14.8358 - val_accuracy: 0.0339\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1011 - accuracy: 0.9615 - val_loss: 15.0963 - val_accuracy: 0.0276\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0906 - accuracy: 0.9682 - val_loss: 13.6490 - val_accuracy: 0.0182\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0924 - accuracy: 0.9692 - val_loss: 15.7988 - val_accuracy: 0.0177\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1029 - accuracy: 0.9615 - val_loss: 14.6830 - val_accuracy: 0.0203\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0945 - accuracy: 0.9657 - val_loss: 14.0513 - val_accuracy: 0.0115\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0819 - accuracy: 0.9711 - val_loss: 15.0862 - val_accuracy: 0.0240\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0844 - accuracy: 0.9683 - val_loss: 16.2425 - val_accuracy: 0.0282\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.0865 - accuracy: 0.9668 - val_loss: 16.5537 - val_accuracy: 0.0151\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.0942 - accuracy: 0.9674 - val_loss: 16.2460 - val_accuracy: 0.0109\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0781 - accuracy: 0.9741 - val_loss: 14.8710 - val_accuracy: 0.0245\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0747 - accuracy: 0.9720 - val_loss: 17.5066 - val_accuracy: 0.0240\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0704 - accuracy: 0.9737 - val_loss: 16.1398 - val_accuracy: 0.0141\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.0856 - accuracy: 0.9702 - val_loss: 16.8723 - val_accuracy: 0.0224\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 0.0796 - accuracy: 0.9733 - val_loss: 14.3989 - val_accuracy: 0.0240\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.0534 - accuracy: 0.9807 - val_loss: 15.7138 - val_accuracy: 0.0182\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0691 - accuracy: 0.9772 - val_loss: 15.1902 - val_accuracy: 0.0209\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.0755 - accuracy: 0.9741 - val_loss: 12.9494 - val_accuracy: 0.0151\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0656 - accuracy: 0.9754 - val_loss: 19.6569 - val_accuracy: 0.0266\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.0567 - accuracy: 0.9798 - val_loss: 16.7607 - val_accuracy: 0.0308\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.0672 - accuracy: 0.9767 - val_loss: 15.8973 - val_accuracy: 0.0271\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 0.0534 - accuracy: 0.9807 - val_loss: 19.4263 - val_accuracy: 0.0282\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0503 - accuracy: 0.9807 - val_loss: 20.4422 - val_accuracy: 0.0334\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0537 - accuracy: 0.9828 - val_loss: 18.9465 - val_accuracy: 0.0224\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0535 - accuracy: 0.9816 - val_loss: 17.9904 - val_accuracy: 0.0292\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0643 - accuracy: 0.9760 - val_loss: 19.1174 - val_accuracy: 0.0224\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0547 - accuracy: 0.9814 - val_loss: 21.7642 - val_accuracy: 0.0276\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.0470 - accuracy: 0.9827 - val_loss: 20.1613 - val_accuracy: 0.0240\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0586 - accuracy: 0.9812 - val_loss: 17.7087 - val_accuracy: 0.0255\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0491 - accuracy: 0.9820 - val_loss: 18.2555 - val_accuracy: 0.0266\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0458 - accuracy: 0.9842 - val_loss: 18.7744 - val_accuracy: 0.0214\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0424 - accuracy: 0.9836 - val_loss: 14.7855 - val_accuracy: 0.0240\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0536 - accuracy: 0.9795 - val_loss: 16.7463 - val_accuracy: 0.0167\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 14.5873 - val_accuracy: 0.0193\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0398 - accuracy: 0.9851 - val_loss: 18.1657 - val_accuracy: 0.0328\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0365 - accuracy: 0.9875 - val_loss: 17.7715 - val_accuracy: 0.0261\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0404 - accuracy: 0.9853 - val_loss: 17.1806 - val_accuracy: 0.0167\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0329 - accuracy: 0.9872 - val_loss: 20.6729 - val_accuracy: 0.0250\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 15.9419 - val_accuracy: 0.0276\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 15.7775 - val_accuracy: 0.0250\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 6s 47ms/step - loss: 0.0342 - accuracy: 0.9888 - val_loss: 18.1426 - val_accuracy: 0.0292\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0458 - accuracy: 0.9838 - val_loss: 17.6849 - val_accuracy: 0.0302\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 18.1894 - val_accuracy: 0.0120\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0301 - accuracy: 0.9915 - val_loss: 15.7455 - val_accuracy: 0.0177\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 19.7020 - val_accuracy: 0.0188\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.0549 - accuracy: 0.9812 - val_loss: 17.2025 - val_accuracy: 0.0261\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 0.0489 - accuracy: 0.9833 - val_loss: 17.5374 - val_accuracy: 0.0235\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0261 - accuracy: 0.9906 - val_loss: 20.5525 - val_accuracy: 0.0276\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 17.8816 - val_accuracy: 0.0360\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0344 - accuracy: 0.9889 - val_loss: 16.3553 - val_accuracy: 0.0167\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 18.3712 - val_accuracy: 0.0209\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0273 - accuracy: 0.9883 - val_loss: 19.9386 - val_accuracy: 0.0245\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0289 - accuracy: 0.9913 - val_loss: 18.2453 - val_accuracy: 0.0198\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0378 - accuracy: 0.9855 - val_loss: 16.7472 - val_accuracy: 0.0355\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0460 - accuracy: 0.9841 - val_loss: 13.9582 - val_accuracy: 0.0162\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0439 - accuracy: 0.9844 - val_loss: 15.6755 - val_accuracy: 0.0177\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0332 - accuracy: 0.9876 - val_loss: 17.2595 - val_accuracy: 0.0130\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 18.5071 - val_accuracy: 0.0224\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 20.2387 - val_accuracy: 0.0109\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 20.3676 - val_accuracy: 0.0297\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 18.2637 - val_accuracy: 0.0240\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 16.4249 - val_accuracy: 0.0224\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 19.6667 - val_accuracy: 0.0261\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0304 - accuracy: 0.9879 - val_loss: 21.1243 - val_accuracy: 0.0167\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 20.5343 - val_accuracy: 0.0219\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0263 - accuracy: 0.9900 - val_loss: 20.6906 - val_accuracy: 0.0245\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 14.5376 - val_accuracy: 0.0172\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.0221 - accuracy: 0.9918 - val_loss: 16.3324 - val_accuracy: 0.0167\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 16.1261 - val_accuracy: 0.0172\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 18.8211 - val_accuracy: 0.0266\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0286 - accuracy: 0.9901 - val_loss: 17.4291 - val_accuracy: 0.0266\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 20.8173 - val_accuracy: 0.0276\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 17.5843 - val_accuracy: 0.0089\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0289 - accuracy: 0.9904 - val_loss: 18.0266 - val_accuracy: 0.0120\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 15.4880 - val_accuracy: 0.0167\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 18.1300 - val_accuracy: 0.0052\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 20.7487 - val_accuracy: 0.0193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2746988fb80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(np.array(X_train).astype('float32'), Y_train_categorical, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c9a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba630814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 24ms/step - loss: 5.3409 - accuracy: 0.6044\n",
      "27/27 [==============================] - 1s 6ms/step\n",
      "Test Loss: 5.340921878814697\n",
      "Test Accuracy: 0.6043890714645386\n",
      "Accuracy: 0.6043890865954923\n",
      "F1 Score: 0.5437447255985512\n",
      "Balanced Accuracy: 0.3379712255358807\n",
      "Cohen Kappa Score:\n",
      "0.2352167374411619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "batch_size = 64\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test_categorical))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(\"Cohen Kappa Score:\")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k = cohen_kappa_score(Y_test, predicted_labels, weights='quadratic')\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf79af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3add546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 16, 16, 32)        864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 16, 16, 32)       128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)       288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 16, 16, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 16, 16, 64)        2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 16, 16, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 17, 17, 64)        0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)         576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 8, 8, 64)         256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 8, 8, 128)         8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 8, 8, 128)        512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)        1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 8, 8, 128)        512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 8, 8, 128)         16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 8, 8, 128)        512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 9, 9, 128)         0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)        1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 4, 4, 128)        512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 4, 4, 256)         32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 4, 4, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)        2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 4, 4, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 4, 4, 256)         65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 4, 4, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 2, 2, 256)        2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 2, 2, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 2, 2, 512)         131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 2, 2, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 2, 2, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 2, 2, 512)         262144    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 2, 2, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 2, 2, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 2, 2, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 2, 2, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 2, 2, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 2, 2, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 2, 2, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 2, 2, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 2, 2, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 3, 3, 512)        0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 1, 1, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 1, 1, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 1, 1, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 1, 1, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 1, 1, 1024)       9216      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 1, 1, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 1, 1, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 1, 1, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1024)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 4100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,232,964\n",
      "Trainable params: 3,211,076\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m new_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m new_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[43mAdam\u001b[49m(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m new_model\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(X_train)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m), Y_train_categorical, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"C:\\Users\\shaif\\Downloads\\Compressed\\Pre-Trained_Models\\Pre-Trained_Models\\limuc_mob_32_model.h5\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "num_classes = 4\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "new_model.summary()\n",
    "# Compile the model\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "new_model.fit(np.array(X_train).astype('float32'), Y_train_categorical, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "394bdf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 17ms/step - loss: 3.8240 - accuracy: 0.5996\n",
      "27/27 [==============================] - 1s 18ms/step\n",
      "Test Loss: 3.823970079421997\n",
      "Test Accuracy: 0.599644124507904\n",
      "Accuracy: 0.599644128113879\n",
      "F1 Score: 0.5201740133923423\n",
      "Balanced Accuracy: 0.3148642823858341\n",
      "Cohen Kappa Score:\n",
      "0.19699459057737745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "batch_size = 64\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test_categorical))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = new_model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(test_dataset)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(\"Cohen Kappa Score:\")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k = cohen_kappa_score(Y_test, predicted_labels, weights='quadratic')\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d9482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a65728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2399a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f8666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
